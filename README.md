# tuned-llm
Code for fine tuning llama based LLMs with data or instructions, using torch 

# Pre-requisites

This project uses miniconda to handle dependencies. The environment is contained in llama-cuda.yaml, which is set up to use CUDA version 1.2.6. It may need to be adjusted depending on the version you have available.

Also requires a valid hugging face token.


